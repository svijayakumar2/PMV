2025-11-06 08:17:10,260 - INFO - ======================================================================
2025-11-06 08:17:10,260 - INFO - MULTIPLICATIVE GATING TRANSFORMER - FULL BENCHMARK
2025-11-06 08:17:10,260 - INFO - ======================================================================
2025-11-06 08:17:10,260 - INFO - Device: cuda
2025-11-06 08:17:10,261 - INFO - Runs per task: 5
2025-11-06 08:17:10,261 - INFO - Results directory: benchmark_results
2025-11-06 08:17:10,261 - INFO - Model config: {'d_model': 256, 'n_layers': 4, 'n_heads': 6, 'n_multiplicative_heads': 2}
2025-11-06 08:17:10,261 - INFO - Running 5 repetitions per task
2025-11-06 08:17:10,261 - INFO - 
======================================================================
2025-11-06 08:17:10,261 - INFO - TASK 1/4: parity_10_2
2025-11-06 08:17:10,261 - INFO - ======================================================================
2025-11-06 08:17:10,294 - INFO -   [Seed 42] Generating data...
2025-11-06 08:17:11,185 - INFO -   [Seed 42] Creating model...
2025-11-06 08:17:11,560 - INFO -   [Seed 42] Training...
2025-11-06 08:17:14,387 - INFO - Training: 500 samples, 1000 steps
2025-11-06 08:17:17,458 - INFO -   Step   0/1000: Loss = 0.7645, Acc = 0.438
2025-11-06 08:17:57,020 - INFO -   Step  25/1000: Loss = 0.6969, Acc = 0.531
2025-11-06 08:18:35,782 - INFO -   Step  50/1000: Loss = 0.6685, Acc = 0.562
2025-11-06 08:19:14,341 - INFO -   Step  75/1000: Loss = 0.6699, Acc = 0.594
2025-11-06 08:19:53,084 - INFO -   Step 100/1000: Loss = 0.7224, Acc = 0.469
2025-11-06 08:20:31,508 - INFO -   Step 125/1000: Loss = 0.6361, Acc = 0.594
2025-11-06 08:21:11,304 - INFO -   Step 150/1000: Loss = 0.6566, Acc = 0.562
2025-11-06 08:21:50,122 - INFO -   Step 175/1000: Loss = 0.5759, Acc = 0.719
2025-11-06 08:22:28,366 - INFO -   Step 200/1000: Loss = 0.6084, Acc = 0.656
2025-11-06 08:23:06,387 - INFO -   Step 225/1000: Loss = 0.6444, Acc = 0.656
2025-11-06 08:23:44,596 - INFO -   Step 250/1000: Loss = 0.6286, Acc = 0.531
2025-11-06 08:24:22,697 - INFO -   Step 275/1000: Loss = 0.5586, Acc = 0.812
2025-11-06 08:25:00,798 - INFO -   Step 300/1000: Loss = 0.5241, Acc = 0.781
2025-11-06 08:25:38,933 - INFO -   Step 325/1000: Loss = 0.5315, Acc = 0.750
2025-11-06 08:26:17,024 - INFO -   Step 350/1000: Loss = 0.4799, Acc = 0.812
2025-11-06 08:26:55,371 - INFO -   Step 375/1000: Loss = 0.5199, Acc = 0.750
2025-11-06 08:27:33,943 - INFO -   Step 400/1000: Loss = 0.4514, Acc = 0.750
2025-11-06 08:28:12,331 - INFO -   Step 425/1000: Loss = 0.5108, Acc = 0.688
2025-11-06 08:28:50,330 - INFO -   Step 450/1000: Loss = 0.4827, Acc = 0.938
2025-11-06 08:29:28,806 - INFO -   Step 475/1000: Loss = 0.4314, Acc = 0.781
2025-11-06 08:30:06,993 - INFO -   Step 500/1000: Loss = 0.5002, Acc = 0.781
2025-11-06 08:30:45,189 - INFO -   Step 525/1000: Loss = 0.3823, Acc = 0.875
2025-11-06 08:31:23,336 - INFO -   Step 550/1000: Loss = 0.3983, Acc = 0.812
2025-11-06 08:32:01,698 - INFO -   Step 575/1000: Loss = 0.3311, Acc = 0.875
2025-11-06 08:32:39,792 - INFO -   Step 600/1000: Loss = 0.2162, Acc = 0.906
2025-11-06 08:33:17,807 - INFO -   Step 625/1000: Loss = 0.5040, Acc = 0.844
2025-11-06 08:33:22,395 - INFO -   → Early stopping at step 628 with 1.000 accuracy
2025-11-06 08:33:22,413 - INFO -   [Seed 42] Evaluating...
2025-11-06 08:33:38,758 - INFO -   [Seed 42] Result: 0.864 accuracy
2025-11-06 08:33:38,793 - INFO -   [Seed 43] Generating data...
2025-11-06 08:33:39,660 - INFO -   [Seed 43] Creating model...
2025-11-06 08:33:39,731 - INFO -   [Seed 43] Training...
2025-11-06 08:33:39,734 - INFO - Training: 500 samples, 1000 steps
2025-11-06 08:33:41,245 - INFO -   Step   0/1000: Loss = 1.0217, Acc = 0.531
2025-11-06 08:34:19,547 - INFO -   Step  25/1000: Loss = 0.8125, Acc = 0.500
2025-11-06 08:34:58,291 - INFO -   Step  50/1000: Loss = 0.6906, Acc = 0.500
2025-11-06 08:35:37,203 - INFO -   Step  75/1000: Loss = 0.6830, Acc = 0.594
2025-11-06 08:36:16,168 - INFO -   Step 100/1000: Loss = 0.6835, Acc = 0.625
2025-11-06 08:36:54,974 - INFO -   Step 125/1000: Loss = 0.7653, Acc = 0.469
2025-11-06 08:37:33,855 - INFO -   Step 150/1000: Loss = 0.6367, Acc = 0.625
2025-11-06 08:38:12,654 - INFO -   Step 175/1000: Loss = 0.7030, Acc = 0.500
2025-11-06 08:38:51,538 - INFO -   Step 200/1000: Loss = 0.5872, Acc = 0.656
2025-11-06 08:39:30,307 - INFO -   Step 225/1000: Loss = 0.6789, Acc = 0.656
2025-11-06 08:40:09,155 - INFO -   Step 250/1000: Loss = 0.6976, Acc = 0.562
2025-11-06 08:40:47,430 - INFO -   Step 275/1000: Loss = 0.7117, Acc = 0.750
2025-11-06 08:41:25,599 - INFO -   Step 300/1000: Loss = 0.5613, Acc = 0.625
2025-11-06 08:42:03,616 - INFO -   Step 325/1000: Loss = 0.5655, Acc = 0.719
2025-11-06 08:42:41,769 - INFO -   Step 350/1000: Loss = 0.5934, Acc = 0.688
2025-11-06 08:43:19,909 - INFO -   Step 375/1000: Loss = 0.6100, Acc = 0.656
2025-11-06 08:43:58,266 - INFO -   Step 400/1000: Loss = 0.5552, Acc = 0.688
2025-11-06 08:44:37,024 - INFO -   Step 425/1000: Loss = 0.3806, Acc = 0.844
2025-11-06 08:45:15,722 - INFO -   Step 450/1000: Loss = 0.3449, Acc = 0.781
2025-11-06 08:45:54,427 - INFO -   Step 475/1000: Loss = 0.2623, Acc = 0.875
2025-11-06 08:46:32,596 - INFO -   Step 500/1000: Loss = 0.3956, Acc = 0.750
2025-11-06 08:47:03,094 - INFO -   → Early stopping at step 520 with 1.000 accuracy
2025-11-06 08:47:03,100 - INFO -   [Seed 43] Evaluating...
2025-11-06 08:47:19,621 - INFO -   [Seed 43] Result: 0.874 accuracy
2025-11-06 08:47:19,651 - INFO -   [Seed 44] Generating data...
2025-11-06 08:47:20,519 - INFO -   [Seed 44] Creating model...
2025-11-06 08:47:20,585 - INFO -   [Seed 44] Training...
2025-11-06 08:47:20,588 - INFO - Training: 500 samples, 1000 steps
2025-11-06 08:47:22,100 - INFO -   Step   0/1000: Loss = 0.8742, Acc = 0.500
2025-11-06 08:48:00,103 - INFO -   Step  25/1000: Loss = 0.6393, Acc = 0.594
2025-11-06 08:48:38,138 - INFO -   Step  50/1000: Loss = 0.6845, Acc = 0.562
2025-11-06 08:49:16,226 - INFO -   Step  75/1000: Loss = 0.6904, Acc = 0.500
2025-11-06 08:49:54,346 - INFO -   Step 100/1000: Loss = 0.6481, Acc = 0.594
2025-11-06 08:50:32,371 - INFO -   Step 125/1000: Loss = 0.6587, Acc = 0.625
2025-11-06 08:51:10,452 - INFO -   Step 150/1000: Loss = 0.5933, Acc = 0.719
2025-11-06 08:51:48,469 - INFO -   Step 175/1000: Loss = 0.6044, Acc = 0.719
2025-11-06 08:52:26,585 - INFO -   Step 200/1000: Loss = 0.6668, Acc = 0.562
2025-11-06 08:53:05,036 - INFO -   Step 225/1000: Loss = 0.5457, Acc = 0.688
2025-11-06 08:53:43,411 - INFO -   Step 250/1000: Loss = 0.6113, Acc = 0.656
2025-11-06 08:54:21,716 - INFO -   Step 275/1000: Loss = 0.6278, Acc = 0.625
2025-11-06 08:55:00,075 - INFO -   Step 300/1000: Loss = 0.5914, Acc = 0.594
2025-11-06 08:55:38,456 - INFO -   Step 325/1000: Loss = 0.4949, Acc = 0.781
2025-11-06 08:56:16,820 - INFO -   Step 350/1000: Loss = 0.5180, Acc = 0.750
2025-11-06 08:56:55,192 - INFO -   Step 375/1000: Loss = 0.6042, Acc = 0.625
2025-11-06 08:57:33,331 - INFO -   Step 400/1000: Loss = 0.5157, Acc = 0.688
2025-11-06 08:58:11,568 - INFO -   Step 425/1000: Loss = 0.8086, Acc = 0.625
2025-11-06 08:58:49,855 - INFO -   Step 450/1000: Loss = 0.6754, Acc = 0.719
2025-11-06 08:59:28,189 - INFO -   Step 475/1000: Loss = 0.5508, Acc = 0.812
2025-11-06 09:00:07,560 - INFO -   Step 500/1000: Loss = 0.5831, Acc = 0.750
2025-11-06 09:00:46,102 - INFO -   Step 525/1000: Loss = 0.4141, Acc = 0.750
2025-11-06 09:01:24,635 - INFO -   Step 550/1000: Loss = 0.4442, Acc = 0.844
2025-11-06 09:02:03,054 - INFO -   Step 575/1000: Loss = 0.3563, Acc = 0.875
2025-11-06 09:02:41,541 - INFO -   Step 600/1000: Loss = 0.1882, Acc = 0.938
2025-11-06 09:03:19,831 - INFO -   Step 625/1000: Loss = 0.4360, Acc = 0.781
2025-11-06 09:03:58,073 - INFO -   Step 650/1000: Loss = 0.1332, Acc = 0.938
2025-11-06 09:04:36,310 - INFO -   Step 675/1000: Loss = 0.3227, Acc = 0.906
2025-11-06 09:05:14,685 - INFO -   Step 700/1000: Loss = 0.2417, Acc = 0.938
2025-11-06 09:05:17,795 - INFO -   → Early stopping at step 702 with 1.000 accuracy
2025-11-06 09:05:17,806 - INFO -   [Seed 44] Evaluating...
2025-11-06 09:05:34,221 - INFO -   [Seed 44] Result: 0.922 accuracy
2025-11-06 09:05:34,249 - INFO -   [Seed 45] Generating data...
2025-11-06 09:05:35,123 - INFO -   [Seed 45] Creating model...
2025-11-06 09:05:35,188 - INFO -   [Seed 45] Training...
2025-11-06 09:05:35,191 - INFO - Training: 500 samples, 1000 steps
2025-11-06 09:05:36,724 - INFO -   Step   0/1000: Loss = 0.6721, Acc = 0.562
2025-11-06 09:06:15,395 - INFO -   Step  25/1000: Loss = 0.7095, Acc = 0.594
2025-11-06 09:06:54,091 - INFO -   Step  50/1000: Loss = 0.7079, Acc = 0.500
2025-11-06 09:07:32,671 - INFO -   Step  75/1000: Loss = 0.6665, Acc = 0.750
2025-11-06 09:08:11,398 - INFO -   Step 100/1000: Loss = 0.6839, Acc = 0.531
2025-11-06 09:08:50,082 - INFO -   Step 125/1000: Loss = 0.6734, Acc = 0.594
2025-11-06 09:09:28,701 - INFO -   Step 150/1000: Loss = 0.6557, Acc = 0.562
2025-11-06 09:10:07,408 - INFO -   Step 175/1000: Loss = 0.6352, Acc = 0.750
2025-11-06 09:10:46,089 - INFO -   Step 200/1000: Loss = 0.6845, Acc = 0.562
2025-11-06 09:11:24,640 - INFO -   Step 225/1000: Loss = 0.6131, Acc = 0.625
2025-11-06 09:12:03,178 - INFO -   Step 250/1000: Loss = 0.6643, Acc = 0.625
2025-11-06 09:12:41,828 - INFO -   Step 275/1000: Loss = 0.5895, Acc = 0.688
2025-11-06 09:13:20,456 - INFO -   Step 300/1000: Loss = 0.6556, Acc = 0.625
2025-11-06 09:13:59,318 - INFO -   Step 325/1000: Loss = 0.6546, Acc = 0.656
2025-11-06 09:14:38,066 - INFO -   Step 350/1000: Loss = 0.5339, Acc = 0.656
2025-11-06 09:15:16,863 - INFO -   Step 375/1000: Loss = 0.5593, Acc = 0.688
2025-11-06 09:15:55,603 - INFO -   Step 400/1000: Loss = 0.4531, Acc = 0.781
2025-11-06 09:16:34,256 - INFO -   Step 425/1000: Loss = 0.3868, Acc = 0.875
2025-11-06 09:17:12,950 - INFO -   Step 450/1000: Loss = 0.4270, Acc = 0.844
2025-11-06 09:17:51,552 - INFO -   Step 475/1000: Loss = 0.4273, Acc = 0.844
2025-11-06 09:18:30,173 - INFO -   Step 500/1000: Loss = 0.3062, Acc = 0.844
2025-11-06 09:19:08,854 - INFO -   Step 525/1000: Loss = 0.2775, Acc = 0.844
2025-11-06 09:19:47,520 - INFO -   Step 550/1000: Loss = 0.3355, Acc = 0.844
2025-11-06 09:20:26,198 - INFO -   Step 575/1000: Loss = 0.1681, Acc = 0.906
